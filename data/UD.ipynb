{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Universal Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import glob\n",
    "import pickle\n",
    "import logging\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "from io import StringIO\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "tqdm.monitor_interval = 0\n",
    "import spacy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "logging.basicConfig(filename='logs/UD.log', filemode='w', level=logging.INFO, \n",
    "                        format='%(asctime)s %(message)s', datefmt='%m/%d/%Y %I:%M:%S %p')\n",
    "\n",
    "EN_LINKS = ['https://github.com/UniversalDependencies/UD_English-ParTUT.git',\n",
    "             'https://github.com/UniversalDependencies/UD_English-GUM.git',\n",
    "             'https://github.com/UniversalDependencies/UD_English-EWT.git',\n",
    "             'https://github.com/UniversalDependencies/UD_English-PUD.git',\n",
    "             'https://github.com/UniversalDependencies/UD_English-LinES.git']\n",
    "\n",
    "FR_LINKS = ['https://github.com/UniversalDependencies/UD_French-ParTUT.git',\n",
    "             'https://github.com/UniversalDependencies/UD_French-GSD.git',\n",
    "             'https://github.com/UniversalDependencies/UD_French-Sequoia.git',\n",
    "             'https://github.com/UniversalDependencies/UD_French-PUD.git',\n",
    "             #'https://github.com/UniversalDependencies/UD_French-FTB.git' # licence restrictions so must copy in\n",
    "            ]\n",
    "\n",
    "IT_LINKS = ['https://github.com/UniversalDependencies/UD_Italian-ISDT.git',\n",
    "             'https://github.com/UniversalDependencies/UD_Italian-ParTUT.git',\n",
    "             'https://github.com/UniversalDependencies/UD_Italian-PUD.git']\n",
    "\n",
    "ES_LINKS = ['https://github.com/UniversalDependencies/UD_Spanish-AnCora.git',\n",
    "            'https://github.com/UniversalDependencies/UD_Spanish-GSD.git',\n",
    "            'https://github.com/UniversalDependencies/UD_Spanish-PUD.git']\n",
    "\n",
    "\n",
    "DATASETS = {'en': EN_LINKS,\n",
    "            'fr': FR_LINKS,\n",
    "            'it': IT_LINKS,\n",
    "            'es':  ES_LINKS}\n",
    "\n",
    "OUT_DIR = 'UD'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 5614.86it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 4902.75it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 4696.87it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 4735.76it/s]\n"
     ]
    }
   ],
   "source": [
    "def download(url, path):\n",
    "    cmd = 'git clone {} {}'.format(url, path)\n",
    "    os.system(cmd)\n",
    "\n",
    "def fetch_datasets(datasets):\n",
    "    for lg, links in datasets.items():\n",
    "        for link in tqdm(links):\n",
    "            dirname = os.path.splitext(os.path.basename(link))[0]\n",
    "            local_path = os.path.join(OUT_DIR, lg, dirname)\n",
    "            if not os.path.exists(local_path):\n",
    "                download(link, local_path)\n",
    "\n",
    "fetch_datasets(DATASETS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Sentence:\n",
    "    \n",
    "    TEXT_PATTERN = re.compile(r'#\\s+?text\\s+?=\\s+?(.*)\\n')\n",
    "    WORDLINES_PATTERN = re.compile(r'\\n(1.*\\n)\\n', re.DOTALL)\n",
    "    TENSE_PATTERN = re.compile(r'Tense=([A-Z0-9][a-zA-Z0-9]*)')\n",
    "    VERBFORM_PATTERN = re.compile(r'VerbForm=([A-Z0-9][a-zA-Z0-9]*)')\n",
    "    NULL_VALUE = '_'\n",
    "    COLUMNS = ['id', 'form', 'lemma', 'upos', 'xpos', 'feats', 'head', 'deprel', 'deps', 'misc']\n",
    "    \n",
    "    def __init__(self, raw):\n",
    "        self.text = self.TEXT_PATTERN.search(raw).group(1)\n",
    "        self.words = self.parse_words(raw)\n",
    "        self.root_id = self.words[self.words['head'] == '0'].index[0]\n",
    "        self.tense_id = self.find_tense_id()\n",
    "        self.extract_features()\n",
    "    \n",
    "    def parse_words(self, raw):\n",
    "        words = self.WORDLINES_PATTERN.search(raw).group(1)\n",
    "        words = pd.read_csv(StringIO(words), sep='\\t', names=self.COLUMNS, quoting=3, dtype={'id': str, 'head': str})\n",
    "        is_emptynode = words['id'].str.contains(r'\\.')\n",
    "        words = words[~is_emptynode]\n",
    "        words.set_index('id', inplace=True)\n",
    "        words['tense'] = words['feats'].str.extract(self.TENSE_PATTERN)\n",
    "        words['verbform'] = words['feats'].str.extract(self.VERBFORM_PATTERN)\n",
    "        words.fillna('_', inplace=True)\n",
    "        words['multiword'] = self.NULL_VALUE\n",
    "        is_range = words.index.str.contains('-')\n",
    "        for idx in words.index[is_range]:\n",
    "            start, end = idx.split('-')\n",
    "            ids = map(str, range(int(start), int(end)+1))\n",
    "            for i in ids:\n",
    "                words.loc[i]['multiword'] = idx\n",
    "        return words.drop(['xpos', 'feats', 'deps', 'misc'], axis=1)\n",
    "         \n",
    "    def extract_features(self):\n",
    "        self.length = len(self.words[self.words['multiword'] == self.NULL_VALUE])\n",
    "        if self.tense_id is not None:\n",
    "            self.tense = self.words.loc[self.tense_id]['tense']\n",
    "            self.tense_wordform = self.get_tensed_wordform()\n",
    "            self.tense_lemma = self.words.loc[self.tense_id]['lemma']\n",
    "            self.relation_to_head = self.words.loc[self.tense_id]['deprel']\n",
    "            \n",
    "            all_tensed_words = self.words[self.words['tense'] != self.NULL_VALUE]\n",
    "            self.other_tensed_words = len(all_tensed_words) - 1\n",
    "            self.other_tensed_words_conflicting = (all_tensed_words['tense'] != self.tense).sum()\n",
    "            \n",
    "            next_word = str(int(self.tense_id)+1)\n",
    "            if int(next_word) > int(self.words.index[-1]):\n",
    "                self.dist_from_right = 0\n",
    "                self.other_tensed_words_right = 0\n",
    "                self.other_tensed_words_conflicting_right = 0\n",
    "            else:\n",
    "                words_to_the_right = self.words.loc[next_word:]\n",
    "                self.dist_from_right = (words_to_the_right['multiword'] == self.NULL_VALUE).sum()\n",
    "                tensed_words_to_the_right = words_to_the_right[words_to_the_right['tense'] != self.NULL_VALUE]\n",
    "                self.other_tensed_words_right = len(tensed_words_to_the_right)\n",
    "                self.other_tensed_words_conflicting_right = (tensed_words_to_the_right['tense'] != self.tense).sum()\n",
    "             \n",
    "        else:\n",
    "            self.tense = None\n",
    "            self.tense_wordform = None\n",
    "            self.tense_lemma = None\n",
    "            self.relation_to_head = None\n",
    "            self.dist_from_right = None \n",
    "            self.other_tensed_words = None\n",
    "            self.other_tensed_words_conflicting = None\n",
    "            self.other_tensed_words_right = None\n",
    "            self.other_tensed_words_conflicting_right = None\n",
    "    \n",
    "    def get_tensed_wordform(self):\n",
    "        multiword_id = self.words.loc[self.tense_id]['multiword']\n",
    "        if multiword_id != self.NULL_VALUE:\n",
    "            return self.words.loc[multiword_id]['form']\n",
    "        return self.words.loc[self.tense_id]['form']\n",
    "\n",
    "class EnglishSentence(Sentence):\n",
    "    \n",
    "    def find_tense_id(self):\n",
    "        \"\"\"\n",
    "        1) AUX direct dependent of root, related by (aux, cop or aux:pass), is finite and has tense\n",
    "        2) If found above but no tense, \n",
    "            if lemma is will, take\n",
    "            otherwise UD is wrong\n",
    "        3) VERB that is root, is finite and has tense\n",
    "        \"\"\"\n",
    "        is_aux = self.words['upos'] == 'AUX'\n",
    "        is_dep_head = self.words['head'] == self.root_id\n",
    "        is_aux_cop_deprel = self.words['deprel'].isin(['aux', 'aux:pass', 'cop'])\n",
    "        is_finite = self.words['verbform'] == 'Fin'\n",
    "        has_tense = self.words['tense'] != self.NULL_VALUE\n",
    "        finite_aux = self.words[is_aux & is_dep_head & is_aux_cop_deprel & is_finite]\n",
    "        \n",
    "        if len(finite_aux):\n",
    "            tensed_finite_aux = finite_aux[has_tense]\n",
    "            if len(tensed_finite_aux):\n",
    "                return tensed_finite_aux.index[0]\n",
    "            elif finite_aux['lemma'][0] == 'will':\n",
    "                return finite_aux.index[0]\n",
    "            else:\n",
    "                return None\n",
    "        else:\n",
    "            root = self.words.loc[self.root_id]\n",
    "            if (root['upos'] == 'VERB') and (root['verbform'] == 'Fin') and (root['tense'] != self.NULL_VALUE):\n",
    "                return self.root_id\n",
    "        return None\n",
    "\n",
    "class ItalianSentence(Sentence):\n",
    "    \n",
    "    def find_tense_id(self):\n",
    "        \"\"\"\"\"\"\n",
    "        root_is_verb = self.words.loc[self.root_id]['upos'] == 'VERB'\n",
    "        root_is_fin = self.words.loc[self.root_id]['verbform'] == 'Fin'\n",
    "        root_has_tense = self.words.loc[self.root_id]['tense'] != self.NULL_VALUE\n",
    "        if root_is_verb and root_is_fin and root_has_tense:\n",
    "            return self.root_id\n",
    "        is_aux = self.words['upos'] == 'AUX'\n",
    "        is_dep_head = self.words['head'] == self.root_id\n",
    "        is_cop = self.words['deprel'] == 'cop'\n",
    "        has_tense = self.words['tense'] != self.NULL_VALUE\n",
    "        is_finite = self.words['verbform'] == 'Fin'\n",
    "        finite_aux = self.words[is_aux & is_dep_head & is_cop & is_finite & has_tense]\n",
    "        if len(finite_aux):\n",
    "            return finite_aux.index[0]\n",
    "        is_aux_pass = self.words['deprel'] == 'aux:pass'\n",
    "        finite_aux_pass = self.words[is_aux & is_dep_head & is_aux_pass & is_finite & has_tense]\n",
    "        root_is_part = self.words.loc[self.root_id]['verbform'] == 'Part'\n",
    "        if len(finite_aux_pass) and root_is_part:\n",
    "            return finite_aux_pass.index[0]\n",
    "        is_aux_deprel = self.words['deprel'] == 'aux'\n",
    "        finite_aux = self.words[is_aux & is_dep_head & is_aux_deprel & is_finite & has_tense]\n",
    "        if len(finite_aux):\n",
    "            is_inf = self.words['verbform'] == 'Inf'\n",
    "            nonfinite_aux = self.words[is_aux & is_dep_head & is_aux_pass & (~has_tense) & is_inf]\n",
    "            if len(nonfinite_aux):\n",
    "                if root_is_verb and root_has_tense and root_is_part:\n",
    "                    return finite_aux.index[0]\n",
    "            is_part = self.words['verbform'] == 'Part'\n",
    "            part_aux = self.words[is_aux & is_dep_head & is_aux_deprel & has_tense & is_part]\n",
    "            root_is_inf = self.words.loc[self.root_id]['verbform'] == 'Inf'\n",
    "            if len(part_aux):\n",
    "                if root_is_verb and (not root_has_tense) and root_is_inf:\n",
    "                    return part_aux.index[0]\n",
    "            if root_is_verb and root_has_tense and root_is_part:\n",
    "                return self.root_id\n",
    "            if root_is_verb and (not root_has_tense) and root_is_inf:\n",
    "                return finite_aux.index[0]\n",
    "        return None\n",
    "        \n",
    "class FrenchSentence(Sentence):\n",
    "    \n",
    "    def find_tense_id(self):\n",
    "        \"\"\"\n",
    "        1) Root is verb, is finite and has tense\n",
    "        2) AUX points to head as aux:pass or cop, has tense and is finite\n",
    "        3) AUX points to head, is aux, has tense, is finite\n",
    "            Root is verb, has tense and is part <-\n",
    "            AUX points to head as cop, has tense and is part <-\n",
    "        \n",
    "        4) Root is verb, is non-finite\n",
    "            AUX points to head, is aux, has tense, is finite\n",
    "                if lemma is \"aller\", future\n",
    "                otherwise AUX\n",
    "        \"\"\"\n",
    "        root_is_verb = self.words.loc[self.root_id]['upos'] == 'VERB'\n",
    "        root_is_fin = self.words.loc[self.root_id]['verbform'] == 'Fin'\n",
    "        root_has_tense = self.words.loc[self.root_id]['tense'] != self.NULL_VALUE\n",
    "        if root_is_verb and root_is_fin and root_has_tense:\n",
    "            return self.root_id\n",
    "        is_aux = self.words['upos'] == 'AUX'\n",
    "        is_dep_head = self.words['head'] == self.root_id\n",
    "        is_finite = self.words['verbform'] == 'Fin'\n",
    "        has_tense = self.words['tense'] != self.NULL_VALUE\n",
    "        finite_aux = self.words[is_aux & is_dep_head & is_finite & has_tense]\n",
    "        if len(finite_aux):\n",
    "            is_auxpass_cop_deprel = self.words['deprel'].isin(['aux:pass', 'cop'])\n",
    "            aux_cop_finite_aux = finite_aux[is_auxpass_cop_deprel]\n",
    "            if len(aux_cop_finite_aux):\n",
    "                return aux_cop_finite_aux.index[0]\n",
    "            else:\n",
    "                if root_is_verb and root_has_tense and self.words.loc[self.root_id]['verbform'] == 'Part':\n",
    "                    return self.root_id\n",
    "                else:\n",
    "                    is_cop = self.words['deprel'] == 'cop'\n",
    "                    is_participle = self.words['verbform'] == 'Part'\n",
    "                    aux = self.words[is_aux & is_dep_head & is_cop & has_tense & is_participle]\n",
    "                    if len(aux):\n",
    "                        return aux.index[0]\n",
    "        if root_is_verb and self.words.loc[self.root_id]['verbform'] == 'Inf':\n",
    "            is_aux_deprel = self.words['deprel'] == 'aux'\n",
    "            aux = self.words[is_aux & is_dep_head & is_aux_deprel & has_tense & is_finite]\n",
    "            if len(aux):\n",
    "                return aux.index[0] # doesn't take aller into account\n",
    "        return None\n",
    "\n",
    "class SpanishSentence(Sentence):\n",
    "    \n",
    "    def find_tense_id(self):\n",
    "        root_is_verb = self.words.loc[self.root_id]['upos'] == 'VERB'\n",
    "        root_is_fin = self.words.loc[self.root_id]['verbform'] == 'Fin'\n",
    "        root_has_tense = self.words.loc[self.root_id]['tense'] != self.NULL_VALUE\n",
    "        if root_is_verb and root_is_fin and root_has_tense:\n",
    "            return self.root_id\n",
    "        is_aux = self.words['upos'] == 'AUX'\n",
    "        is_dep_head = self.words['head'] == self.root_id\n",
    "        is_finite = self.words['verbform'] == 'Fin'\n",
    "        has_tense = self.words['tense'] != self.NULL_VALUE\n",
    "        is_auxpass_aux_deprel = self.words['deprel'].isin(['aux:pass', 'aux'])\n",
    "        finite_aux = self.words[is_aux & is_dep_head & is_finite & has_tense & is_auxpass_aux_deprel]\n",
    "        if len(finite_aux):\n",
    "            root_is_part = self.words.loc[self.root_id]['verbform'] == 'Part'\n",
    "            if root_is_verb and root_has_tense and root_is_part:\n",
    "                return self.root_id\n",
    "        is_verb = self.words['upos'] == 'VERB'\n",
    "        is_cop = self.words['deprel'] == 'cop'\n",
    "        finite_cop = self.words[is_verb & is_dep_head & is_cop & has_tense & is_finite]\n",
    "        if len(finite_cop):\n",
    "            return finite_cop.index[0]\n",
    "        is_aux_deprel = self.words['deprel'] == 'aux'\n",
    "        finite_aux = self.words[is_aux & is_dep_head & is_aux_deprel & has_tense & is_finite]\n",
    "        if len(finite_aux):\n",
    "            root_is_inf = self.words.loc[self.root_id]['verbform'] == 'Inf'\n",
    "            if root_is_verb and (not root_has_tense) and root_is_inf:\n",
    "                return finite_aux.index[0]\n",
    "        return None\n",
    "\n",
    "class CoNLLUReader:\n",
    "    \n",
    "    SENTENCE_PATTERN = re.compile(r'# sent_id.*?\\n\\n', re.DOTALL)\n",
    "    \n",
    "    SENTENCE_READERS = {'en': EnglishSentence,\n",
    "                        'it': ItalianSentence,\n",
    "                        'fr': FrenchSentence,\n",
    "                        'es': SpanishSentence}\n",
    "    \n",
    "    def __init__(self, lg, fname):\n",
    "        self.lg = lg\n",
    "        self.sentences = self.parse_sentences(self.read(fname))\n",
    "        \n",
    "    def read(self, fname):\n",
    "        with open(fname, encoding='utf-8') as f:\n",
    "            return f.read()\n",
    "        \n",
    "    def parse_sentences(self, raw):\n",
    "        SentenceReader = self.SENTENCE_READERS[self.lg]\n",
    "        sentences = []\n",
    "        raw = re.sub('’', \"'\", raw)\n",
    "        for sent in self.SENTENCE_PATTERN.finditer(raw):\n",
    "            sent = SentenceReader(sent.group(0))\n",
    "            sentences.append(sent)\n",
    "        return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class UDReader:\n",
    "    \n",
    "    FEATURES = ['text', 'length', 'tense', 'tense_wordform', 'tense_lemma', 'relation_to_head',\n",
    "                'dist_from_right', 'other_tensed_words', 'other_tensed_words_conflicting',\n",
    "                'other_tensed_words_right', 'other_tensed_words_conflicting_right']\n",
    "    \n",
    "    def __init__(self, lg):\n",
    "        self.lg = lg\n",
    "        nlp = spacy.load(lg, disable=['tagger', 'parser', 'ner', 'textcat'])\n",
    "        self.tokenizer = nlp.tokenizer\n",
    "        self.fnames = glob.glob(os.path.join(OUT_DIR, lg, '**/*.conllu'))\n",
    "        \n",
    "    def prepare(self):\n",
    "        self.tensed_types = set() # built up during prepare_gt_and_tensed_types()\n",
    "        self.ground_truth = self.prepare_gt_and_tensed_types()\n",
    "        self.freq_dist = self.prepare_freq_dist()\n",
    "        self.responsible_types = self.prepare_responsible()\n",
    "        # here is where I make sure that the tensed types and responsible types have the same tokenization\n",
    "        # as the wikipedia data\n",
    "        self.tensed_types = self.ensure_same_tokenization(self.tensed_types.copy())\n",
    "        self.responsible_types = self.ensure_same_tokenization(self.responsible_types.copy())\n",
    "        self.write()\n",
    "    \n",
    "    def ensure_same_tokenization(self, words):\n",
    "        s = ' '.join(words)\n",
    "        result = set()\n",
    "        for token in self.tokenizer(s):\n",
    "            token = token.text\n",
    "            result.add(token)\n",
    "        return result\n",
    "    \n",
    "    def prepare_gt_and_tensed_types(self):\n",
    "        gt = []\n",
    "        for fname in tqdm(self.fnames):\n",
    "            reader = CoNLLUReader(self.lg, fname)\n",
    "            for s in reader.sentences:\n",
    "                if s.tense:\n",
    "                    g = self.extract(s, self.FEATURES)\n",
    "                    gt.append(g)\n",
    "                    self.add_tensed_words(s)\n",
    "        df = pd.DataFrame(gt, columns=self.FEATURES)\n",
    "        df['text'] = df['text'].str.lower()\n",
    "        df['tense_wordform'] = df['tense_wordform'].str.lower()\n",
    "        return df\n",
    "        \n",
    "    def prepare_responsible(self):\n",
    "        return set(self.ground_truth['tense_wordform'])\n",
    "    \n",
    "    def add_tensed_words(self, sent):\n",
    "        ids = sent.words[sent.words['tense'] != Sentence.NULL_VALUE].index\n",
    "        for i in ids:\n",
    "            multiword_i = sent.words.loc[i]['multiword']\n",
    "            if multiword_i != Sentence.NULL_VALUE:\n",
    "                i = multiword_i\n",
    "            t = sent.words.loc[i]['form'].lower()\n",
    "            self.tensed_types.add(t)\n",
    "    \n",
    "    def prepare_freq_dist(self):\n",
    "        freq_dist = Counter()\n",
    "        for sent in self.ground_truth['text']:\n",
    "            tokens = [t.text for t in self.tokenizer(sent)]\n",
    "            freq_dist.update(tokens)\n",
    "        return freq_dist\n",
    "            \n",
    "    def extract(self, sent, features):\n",
    "        return [getattr(sent, ft) for ft in features]\n",
    "    \n",
    "    def write(self):\n",
    "        ofile = os.path.join(OUT_DIR, self.lg, 'ground_truth.csv')\n",
    "        self.ground_truth.to_csv(ofile, index=False)\n",
    "        ofile = os.path.join(OUT_DIR, self.lg, 'metadata.pkl')\n",
    "        obj = {'freq_dist': self.freq_dist, 'tensed_types': self.tensed_types, \n",
    "               'responsible_types': self.responsible_types}\n",
    "        with open(ofile, mode='wb') as f:\n",
    "            pickle.dump(obj, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main(lgs):\n",
    "    for lg in lgs:\n",
    "        start = datetime.now()\n",
    "        reader = UDReader(lg)\n",
    "        reader.prepare()\n",
    "        end = datetime.now()\n",
    "        num_sents = len(reader.ground_truth)\n",
    "        msg = 'Processing {} sentences for {} took {}'.format(num_sents, lg, end-start)\n",
    "        logging.info(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "main(['en', 'fr', 'it', 'es'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Postprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def contains(tokens, types):\n",
    "        \"\"\"Returns whether at least one thing in types is in tokens\"\"\"\n",
    "        return bool(set(tokens).intersection(set(types)))\n",
    "\n",
    "def postprocess_ud(lg):\n",
    "    fname = os.path.join('UD', lg, 'ground_truth.csv')\n",
    "    df = pd.read_csv(fname)\n",
    "    fname = os.path.join('wikipedia', lg, 'metadata.pkl')\n",
    "    with open(fname, 'rb') as f:\n",
    "        obj = pickle.load(f)\n",
    "    wiki_freq_dist = obj['freq_dist']\n",
    "    df['freq_wordform'] = df['tense_wordform'].apply(lambda w: wiki_freq_dist[w])\n",
    "    df['pres_other_tensed_words'] = df['other_tensed_words'] > 0\n",
    "    df['pres_other_tensed_words_conflicting'] = df['other_tensed_words_conflicting'] > 0\n",
    "    df['pres_other_tensed_words_right'] = df['other_tensed_words_right'] > 0\n",
    "    df['pres_other_tensed_words_conflicting_right'] = df['other_tensed_words_conflicting_right'] > 0\n",
    "    fname = os.path.join('wikipedia', lg, 'lemmata.pkl')\n",
    "    with open(fname, 'rb') as f:\n",
    "        lemmata = pickle.load(f)\n",
    "    df['freq_lemma'] = df['tense_lemma'].apply(lambda w: lemmata[w])\n",
    "    fname = os.path.join('UD', lg, 'metadata.pkl')\n",
    "    with open(fname, 'rb') as f:\n",
    "        obj = pickle.load(f)\n",
    "    responsible = obj['responsible_types']\n",
    "    tensed_types = obj['tensed_types']\n",
    "    fname = os.path.join('wikipedia', lg, 'unk-metadata.pkl')\n",
    "    with open(fname, 'rb') as f:\n",
    "        obj = pickle.load(f)\n",
    "    not_in_wiki = obj['not-in-wiki']\n",
    "    missing_tensed = not_in_wiki.intersection(tensed_types)\n",
    "    missing_responsible = not_in_wiki.intersection(responsible)\n",
    "    nlp = spacy.load(lg)\n",
    "    tokenizer = lambda s: [t.text for t in nlp.tokenizer(s)]\n",
    "    df['tokens'] = df['text'].apply(tokenizer)\n",
    "    contains_tensed = lambda tokens: contains(tokens, missing_tensed)\n",
    "    df['contains_tensed'] = df['tokens'].apply(contains_tensed)\n",
    "    contains_responsible = lambda tokens: contains(tokens, missing_responsible)\n",
    "    df['contains_responsible'] = df['tokens'].apply(contains_responsible)\n",
    "    p = 0.7\n",
    "    good_split = False\n",
    "    while not good_split:\n",
    "        train_set = df['tense_wordform'].value_counts().sample(frac=p).index\n",
    "        df['train'] = df['tense_wordform'].isin(train_set)\n",
    "        achieved_p = df['train'].value_counts(normalize=True)[True]\n",
    "        if abs(p-achieved_p) < 0.05:\n",
    "            good_split = True\n",
    "    fname = os.path.join('UD', lg, 'prepared.csv')\n",
    "    df.to_csv(fname, index=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>length</th>\n",
       "      <th>tense</th>\n",
       "      <th>tense_wordform</th>\n",
       "      <th>tense_lemma</th>\n",
       "      <th>relation_to_head</th>\n",
       "      <th>dist_from_right</th>\n",
       "      <th>other_tensed_words</th>\n",
       "      <th>other_tensed_words_conflicting</th>\n",
       "      <th>other_tensed_words_right</th>\n",
       "      <th>...</th>\n",
       "      <th>freq_wordform</th>\n",
       "      <th>pres_other_tensed_words</th>\n",
       "      <th>pres_other_tensed_words_conflicting</th>\n",
       "      <th>pres_other_tensed_words_right</th>\n",
       "      <th>pres_other_tensed_words_conflicting_right</th>\n",
       "      <th>freq_lemma</th>\n",
       "      <th>tokens</th>\n",
       "      <th>contains_tensed</th>\n",
       "      <th>contains_responsible</th>\n",
       "      <th>train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>l'association a changé les décors et avec l'ai...</td>\n",
       "      <td>34</td>\n",
       "      <td>Past</td>\n",
       "      <td>changé</td>\n",
       "      <td>changer</td>\n",
       "      <td>root</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>561</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>3443</td>\n",
       "      <td>[l', association, a, changé, les, décors, et, ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>quant au sous-préfet, il apprécie l'énergie dé...</td>\n",
       "      <td>14</td>\n",
       "      <td>Pres</td>\n",
       "      <td>apprécie</td>\n",
       "      <td>apprécier</td>\n",
       "      <td>root</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>268</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1469</td>\n",
       "      <td>[quant, au, sous-préfet, ,, il, apprécie, l', ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>les membres du club auront l'occasion de s'ent...</td>\n",
       "      <td>20</td>\n",
       "      <td>Fut</td>\n",
       "      <td>auront</td>\n",
       "      <td>avoir</td>\n",
       "      <td>root</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>385</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>290023</td>\n",
       "      <td>[les, membres, du, club, auront, l', occasion,...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>m. hosneld avait 44 ans.</td>\n",
       "      <td>6</td>\n",
       "      <td>Imp</td>\n",
       "      <td>avait</td>\n",
       "      <td>avoir</td>\n",
       "      <td>root</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>14837</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>290023</td>\n",
       "      <td>[m., hosneld, avait, 44, ans, .]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c'est le cas de ce brave joseph bari, toujours...</td>\n",
       "      <td>44</td>\n",
       "      <td>Pres</td>\n",
       "      <td>est</td>\n",
       "      <td>être</td>\n",
       "      <td>cop</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>304797</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>604255</td>\n",
       "      <td>[c', est, le, cas, de, ce, brave, joseph, bari...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  length tense  \\\n",
       "0  l'association a changé les décors et avec l'ai...      34  Past   \n",
       "1  quant au sous-préfet, il apprécie l'énergie dé...      14  Pres   \n",
       "2  les membres du club auront l'occasion de s'ent...      20   Fut   \n",
       "3                           m. hosneld avait 44 ans.       6   Imp   \n",
       "4  c'est le cas de ce brave joseph bari, toujours...      44  Pres   \n",
       "\n",
       "  tense_wordform tense_lemma relation_to_head  dist_from_right  \\\n",
       "0         changé     changer             root               30   \n",
       "1       apprécie   apprécier             root                8   \n",
       "2         auront       avoir             root               15   \n",
       "3          avait       avoir             root                3   \n",
       "4            est        être              cop               42   \n",
       "\n",
       "   other_tensed_words  other_tensed_words_conflicting  \\\n",
       "0                   2                               1   \n",
       "1                   1                               1   \n",
       "2                   0                               0   \n",
       "3                   0                               0   \n",
       "4                   2                               2   \n",
       "\n",
       "   other_tensed_words_right  ...    freq_wordform  pres_other_tensed_words  \\\n",
       "0                         1  ...              561                     True   \n",
       "1                         1  ...              268                     True   \n",
       "2                         0  ...              385                    False   \n",
       "3                         0  ...            14837                    False   \n",
       "4                         2  ...           304797                     True   \n",
       "\n",
       "   pres_other_tensed_words_conflicting  pres_other_tensed_words_right  \\\n",
       "0                                 True                           True   \n",
       "1                                 True                           True   \n",
       "2                                False                          False   \n",
       "3                                False                          False   \n",
       "4                                 True                           True   \n",
       "\n",
       "   pres_other_tensed_words_conflicting_right  freq_lemma  \\\n",
       "0                                      False        3443   \n",
       "1                                       True        1469   \n",
       "2                                      False      290023   \n",
       "3                                      False      290023   \n",
       "4                                       True      604255   \n",
       "\n",
       "                                              tokens contains_tensed  \\\n",
       "0  [l', association, a, changé, les, décors, et, ...           False   \n",
       "1  [quant, au, sous-préfet, ,, il, apprécie, l', ...           False   \n",
       "2  [les, membres, du, club, auront, l', occasion,...           False   \n",
       "3                   [m., hosneld, avait, 44, ans, .]           False   \n",
       "4  [c', est, le, cas, de, ce, brave, joseph, bari...           False   \n",
       "\n",
       "   contains_responsible  train  \n",
       "0                 False  False  \n",
       "1                 False   True  \n",
       "2                 False  False  \n",
       "3                 False   True  \n",
       "4                 False   True  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = postprocess_ud('fr')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
